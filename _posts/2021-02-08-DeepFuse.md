---
layout: single
title: "[논문리뷰] DeepFuse - A Deep Unsupervised Approach for Exposure Fusion with Extreme Exposure Image Pairs"
tage: [MEF]
comments: true
published: true
categories: MEF
use_math: true
typora-copy-images-to: ..\images\DeepFuse
---



**[논문리뷰] DeepFuse - A Deep Unsupervised Approach for Exposure Fusion with Extreme Exposure Image Pairs**



## **HDRI Using CNN**



![image-20210208162612785](/images/DeepFuse/image-20210208162612785.png)



- High Dynamic Range Imaging (HDRI) : 서로 다른 노출을 주어 찍은 여러 장의 사진으로부터 높은 Dynamic Range 를 갖는 사진을 얻는 기법

- RGB를 YCbCr로 변환 후 Y영역에서만 CNN 적용

  

<br/>

<br/>

## **Feature** **extraction layers**

<br/>

![image-20210208162645591](/images/DeepFuse/image-20210208162645591.png)

<br/>

- 5x5 filter로 low-level feature를 추출함 (edge, corner)
- C11,C12 / C21,C22는 같은 weight을 공유함
- F11, F21의 형태가 같아서 간단하게 결합 가능

<br/>

<br/>

## **Fusion** **layer**

![image-20210208162729956](/images/DeepFuse/image-20210208162729956.png)

<br/>

- •이전 layer의 출력인 F11, F21을 결합하기 위해 단순히 더함

  

- Addition으로 인해 learnable filter들이 반으로 줌

  

- 결합을 위한 여러 방법 중 addition이 가장 좋은 성능을 보여줌 (Table 1.)

  

- Concatenation시에는 training iteration을 증가시키면 비슷한 성능을 보여주었음

  

<br/>

<br/>

## **Reconstruction** **layers**

![image-20210208162821090](/images/DeepFuse/image-20210208162821090.png)

<br/>

- 3개의 convolution layer들로 구성

- Fused feature들로부터 최종 결과를 reconstruct함

  

<br/>

<br/>

## 실험 결과

<br/>

![image-20210208162920661](/images/DeepFuse/image-20210208162920661.png)

<br/>

![image-20210208162939014](/images/DeepFuse/image-20210208162939014.png)