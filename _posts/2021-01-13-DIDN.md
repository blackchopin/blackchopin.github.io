---
layout: single
title: "[논문리뷰] DIDN - Deep Iterative Down-Up CNN for Image Denoising"
tage: [Denoising]
comments: true
published: true
categories: Denoising
use_math: true
typora-copy-images-to: ..\images\DIDN
---

<br/>

**[논문리뷰] DIDN - Deep Iterative Down-Up CNN for Image Denoising**

<br/>

## DIDN의 구조

<br/>

![image-20210209170251592](/images/DIDN/image-20210209170251592.png)

<br/>

DIDN (Deep Iterative Down-up Network)

DUB (Down Up Block)

<br/>

<br/>

## **Initial Feature Extraction**

<br/>

![image-20210209170312007](/images/DIDN/image-20210209170312007.png)

<br/>

- 3x3 convolution을 통해 N개의 feature 생성 (N=256)
- stride=2 인 3x3 convolution을 통해 feature의 크기를 줄임 (downsampling) 

<br/>

이후의 모든 downsampling 은 학습이 가능한 stride=2인 conv 로 사용

Pooling, sub-sampling 존재

<br/>

<br/>

## Down-Up Block

<br/>

![image-20210209170402132](/images/DIDN/image-20210209170402132.png)

<br/>

- 구조는 U-net과 유사
- Down sampling은 stride=2인 3x3 convolution을 통해, Up sampling은 subpixel layer를 통해 실행.
- Pixel shuffle 전 1x1 convolution을 통해 feature map 수 증가

<br/>

U-net에서는 max pooling을 사용했지만, DUB에서는 convolution 사용

subpixel이 계산복잡도 낮춤

Down sampling시 채널수 2배, 크기 4배 감소

Up sampling 전에 채널수 2배 증가해야함으로 1x1 conv 사용

<br/>

<br/>

## **Reconstruction**

<br/>

![image-20210209170548506](/images/DIDN/image-20210209170548506.png)

<br/>

- 모든 local output의 정보를 얻기 위해 DUB의 모든 출력을 입력으로 사용
- 9개의 3x3 convolution, PReLU로 구성됨

<br/>

![image-20210209170617998](/images/DIDN/image-20210209170617998.png)

<br/>

Reconstruction의 구조는 아래와 같다.

<br/>

<br/>

## **Enhancement**

<br/>

![image-20210209170645616](/images/DIDN/image-20210209170645616.png)

<br/>

- Reconstruction의 결과를 concat후 1x1 convolution으로 채널 수 낮춤

- DUB와 동일하게 subpixel layer로 up-scaling 수행

- Subpixel layer가 LR서 HR로 디테일한 정보를 전달하기에 denoising에 효율적

  <br/>

<br/>

## **Ensemble strategy**

1. Snapshot ensemble
   - Learning rate를 주기적으로 변경하고, 주기마다 weight의 평균을 냄

2. Self-ensemble

   - 하나의 input에 대해 rotate, flip을 통해 8개의 output 생성

   - 8개의 output의 평균을 최종 결과로 사용

3. Model ensemble

   - 같은 동작을 여러 모델로 수행한 후 output들의 평균 사용

   - DIDN에 적용시 parameter는 증가하지만, 성능변화가 적어 비효율적 

<br/><br/>

## 실험 결과

<br/>

![image-20210209170829447](/images/DIDN/image-20210209170829447.png)